def to_ts(s: pd.Series) -> pd.Series:
    # 直接用 pandas 解析並設成 UTC
    return pd.to_datetime(s, errors="coerce", utc=True)





def write_to_influx(df: pd.DataFrame) -> bool:
    if df.empty:
        print("[INFO] nothing to write.")
        return True
    try:
        # --- 時間欄位正規化（非常重要）---
        if "event_ts" not in df.columns:
            print("[ERROR] no event_ts column; nothing written.")
            return False

        df["event_ts"] = pd.to_datetime(df["event_ts"], errors="coerce", utc=True)
        before = len(df)
        df = df[~df["event_ts"].isna()].copy()
        dropped = before - len(df)
        if dropped > 0:
            print(f"[WARN] dropped {dropped} rows due to invalid event_ts")

        # --- 清掉 pd.NA、處理 dtype ---
        df = _sanitize_for_influx(df)

        # 只帶真的存在的 tag 欄位（避免奇怪型別或不存在欄位搞壞寫入）
        tag_cols_effective = [c for c in TAG_COLS if c in df.columns]

        # --- 關鍵偵錯輸出 ---
        print("[DEBUG] df shape:", df.shape)
        print("[DEBUG] event_ts range:", df["event_ts"].min(), "→", df["event_ts"].max())
        print("[DEBUG] bucket/org/meas:", BUCKET, ORG, MEAS)
        print("[DEBUG] effective TAG_COLS:", tag_cols_effective)

        with InfluxDBClient(url=INFLUX_URL, org=ORG, token=TOKEN) as cli:
            w = cli.write_api(write_options=SYNCHRONOUS)
            w.write(
                bucket=BUCKET,
                org=ORG,
                record=df,
                data_frame_measurement_name=MEAS,
                data_frame_tag_columns=tag_cols_effective,
                data_frame_timestamp_column="event_ts",
            )
        print(f"[OK] wrote {len(df)} rows to {BUCKET}/{MEAS}")
        return True
    except Exception as e:
        print(f"[ERROR] write influx failed: {e}")
        return False